{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-2 (conversion in numerical and model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i come border i kill</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>im get borderland kill</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>im come borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>im get borderland 2 murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>im get borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72722</th>\n",
       "      <td>73716</td>\n",
       "      <td>just realiz window partit mac like 6 year behi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72723</th>\n",
       "      <td>73717</td>\n",
       "      <td>just realiz mac window partit 6 year behind nv...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72724</th>\n",
       "      <td>73718</td>\n",
       "      <td>just realiz window partit mac 6 year behind nv...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72725</th>\n",
       "      <td>73719</td>\n",
       "      <td>just realiz window partit mac like 6 year behi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72726</th>\n",
       "      <td>73720</td>\n",
       "      <td>just like window partit mac like 6 year behind...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72727 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Tweets         0\n",
       "0               0                               i come border i kill  Positive\n",
       "1               1                             im get borderland kill  Positive\n",
       "2               2                          im come borderland murder  Positive\n",
       "3               3                         im get borderland 2 murder  Positive\n",
       "4               4                           im get borderland murder  Positive\n",
       "...           ...                                                ...       ...\n",
       "72722       73716  just realiz window partit mac like 6 year behi...  Positive\n",
       "72723       73717  just realiz mac window partit 6 year behind nv...  Positive\n",
       "72724       73718  just realiz window partit mac 6 year behind nv...  Positive\n",
       "72725       73719  just realiz window partit mac like 6 year behi...  Positive\n",
       "72726       73720  just like window partit mac like 6 year behind...  Positive\n",
       "\n",
       "[72727 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(data.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'0':'sentiments'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "Negative      21999\n",
       "Positive      20286\n",
       "Neutral       17744\n",
       "Irrelevant    12698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets        0\n",
       "sentiments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72727, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['Tweets']\n",
    "Y=data['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer()  \n",
    "X_counts = vectorizer.fit_transform(X)  \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16490)\t0.49331992805185615\n",
      "  (0, 7100)\t0.44168332261717896\n",
      "  (0, 5357)\t0.7493672604996569\n",
      "  (1, 16490)\t0.5925659266269032\n",
      "  (1, 14951)\t0.4248653669990299\n",
      "  (1, 12167)\t0.41025133355170057\n",
      "  (1, 5360)\t0.5477671821537234\n",
      "  (2, 19276)\t0.6983753542273423\n",
      "  (2, 14951)\t0.34834903110868304\n",
      "  (2, 7100)\t0.43499302481634494\n",
      "  (2, 5360)\t0.449116783804171\n",
      "  (3, 19276)\t0.7265589113060767\n",
      "  (3, 14951)\t0.3624069653443998\n",
      "  (3, 12167)\t0.34994130463287315\n",
      "  (3, 5360)\t0.4672412901097615\n",
      "  (4, 19276)\t0.7265589113060767\n",
      "  (4, 14951)\t0.3624069653443998\n",
      "  (4, 12167)\t0.34994130463287315\n",
      "  (4, 5360)\t0.4672412901097615\n",
      "  (5, 31360)\t0.26491731676295543\n",
      "  (5, 30966)\t0.2583159429395332\n",
      "  (5, 26985)\t0.1940141385833085\n",
      "  (5, 26774)\t0.1496033057593737\n",
      "  (5, 26686)\t0.267985295827893\n",
      "  (5, 22255)\t0.3018285630347388\n",
      "  :\t:\n",
      "  (72725, 24093)\t0.2750116682168431\n",
      "  (72725, 21273)\t0.4130336053883051\n",
      "  (72725, 20236)\t0.1974819402518872\n",
      "  (72725, 20111)\t0.2859241909411373\n",
      "  (72725, 17785)\t0.32781459469284197\n",
      "  (72725, 17208)\t0.15046334956513505\n",
      "  (72725, 16187)\t0.21642382809720281\n",
      "  (72725, 14748)\t0.24773821416210165\n",
      "  (72725, 11631)\t0.1598914118763866\n",
      "  (72725, 10202)\t0.1979777964051375\n",
      "  (72725, 9275)\t0.2799935056843615\n",
      "  (72725, 6153)\t0.26735261116360587\n",
      "  (72725, 4487)\t0.27482465359897723\n",
      "  (72726, 32654)\t0.19168938962871482\n",
      "  (72726, 31922)\t0.28030605291596505\n",
      "  (72726, 26686)\t0.20309316459522667\n",
      "  (72726, 21273)\t0.4337956045640148\n",
      "  (72726, 20111)\t0.30029676919915677\n",
      "  (72726, 17785)\t0.3442928818249502\n",
      "  (72726, 17208)\t0.31605340988160935\n",
      "  (72726, 16187)\t0.22730282506485555\n",
      "  (72726, 14748)\t0.2601912943258567\n",
      "  (72726, 9275)\t0.2940679656275363\n",
      "  (72726, 8637)\t0.23978750241851646\n",
      "  (72726, 4487)\t0.28863929036714614\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB as nb\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,recall_score\n",
    "model=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vector=pd.DataFrame(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_data= X_tfidf\n",
    "target=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_test,Y_train,y_test= train_test_split(vectorizer_data,target,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as ds \n",
    "model2= ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.7921077959576516\n",
      "f1 score : 0.7866037621472136\n",
      "recall score : 0.7841486503961789\n",
      "precision score : 0.7899140973007953\n",
      "confusion matrix : [[1815  195  205  315]\n",
      " [ 174 3585  274  337]\n",
      " [ 153  306 2773  314]\n",
      " [ 194  270  287 3349]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"accuracy score :\", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score :\", f1_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"recall score :\", recall_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"precision score :\", precision_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"confusion matrix :\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tweet: fuck you dude\n",
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweet = \"fuck you dude\"\n",
    "tweet_vectorized = vectorizer.transform([tweet])\n",
    "prediction = model2.predict(tweet_vectorized)\n",
    "print(\" Tweet:\", tweet)\n",
    "print(\"Predicted Sentiment:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.7054860442733397\n"
     ]
    }
   ],
   "source": [
    "model3= MultinomialNB()\n",
    "model3.fit(X_train,Y_train)\n",
    "y_pred=model3.predict(x_test)\n",
    "\n",
    "print(\"accuracy score :\", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.1, 'fit_prior': False}\n",
      "Best cross-validation score: 0.7867688965681914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
    "    'fit_prior': [True,False]\n",
    "}\n",
    "clf = MultinomialNB()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validation score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# One-hot encoding for Y_train if needed (for multi-class classification)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Y_train_encoded = to_categorical(Y_train_encoded)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Model creation\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m---> 20\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m), dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming X_train, Y_train, x_test, y_test are defined\n",
    "\n",
    "# Label encoding for Y_train\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "\n",
    "# One-hot encoding for Y_train if needed (for multi-class classification)\n",
    "# Y_train_encoded = to_categorical(Y_train_encoded)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, Y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Inverse transform for multi-class classification if one-hot encoding was used\n",
    "y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred_binary, axis=1))\n",
    "\n",
    "# Evaluation\n",
    "print(\"accuracy score :\", accuracy_score(y_test, y_pred_binary))\n",
    "print(\"f1 score :\", f1_score(y_test, y_pred_binary, average=\"macro\"))\n",
    "print(\"recall score :\", recall_score(y_test, y_pred_binary, average=\"macro\"))\n",
    "print(\"precision score :\", precision_score(y_test, y_pred_binary, average=\"macro\"))\n",
    "print(\"confusion matrix :\", confusion_matrix(y_test, y_pred_binary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
